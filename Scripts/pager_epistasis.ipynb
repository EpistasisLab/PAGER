{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is used to generate exhaustive epistatic features using genotypic data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample datasets are generated using GAMETES:\n",
    "\n",
    "Dataset 1 - Continuous Phenotyoe\n",
    "Dataset 2 - Discrete Phenotype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import all the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations, product\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the function to generate the epistatic features exhaustively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function definition to generate the PAGER epistatis encodings using the training genotypes and phenotype. \n",
    "    \n",
    "    Input Parameters\n",
    "\n",
    "    ----------------\n",
    "    genotypes_train : pandas dataframe\n",
    "        A dataframe containing the training genotypes of the SNPs. The dataframe should have the SNPs as columns and the samples as rows.\n",
    "    phenotype : pandas series\n",
    "        A series containing the training phenotype of the samples. The series should have the samples as index and the phenotypes as values.\n",
    "    order : int\n",
    "        The order of the epistasis to be considered. For example, if order=2, then the function will consider all possible two-way epistasis.\n",
    "\n",
    "    Returns\n",
    "\n",
    "    ----------------\n",
    "    pager_epistatis_mapping : pandas dataframe\n",
    "        A dataframe containing the PAGER epistatic encodings for each SNP combination. The dataframe will have the SNP combination and the corresponding PAGER epistatic encoding.\n",
    "   all_missing_multilocus : pandas dataframe\n",
    "        A dataframe containing all the missing multilocus genotypes for all SNP combinations. The dataframe will have the SNP combination and the corresponding missing multilocus genotypes.\n",
    "    '''\n",
    "\n",
    "def get_pager_epistatis_mapping(genotypes_train, phenotype_train, order):\n",
    "    # All possible SNP/feature combinations for order-way epistasis\n",
    "    snp_combinations = list(combinations(genotypes_train.columns, order))\n",
    "\n",
    "    # All possible genotypic (0,1,2) combinations for order-way epistasis - used to find missing multilocus genotypes\n",
    "    unique_genotypes = genotypes_train.stack().unique()\n",
    "    possible_genotypic_combinations = list(product(unique_genotypes, repeat=order))\n",
    "\n",
    "    # Create a list to hold missing multilocus dataframes for all iterations\n",
    "    missing_multilocus_list = []\n",
    "\n",
    "    pager_epistasis_mapping = []  # List to store all aggregations for each SNP combination - final output of the function\n",
    "\n",
    "    # Loop through all SNP combinations\n",
    "    for snp_combination in snp_combinations:\n",
    "        # Make a DataFrame with the SNP combination and the phenotype\n",
    "        snp_combination_df_train = genotypes_train[list(snp_combination)].copy()\n",
    "        snp_combination_df_train.loc[:, 'Phenotype'] = phenotype_train\n",
    "\n",
    "        snp_columns = list(snp_combination_df_train.columns[:-1])\n",
    "\n",
    "        # Create a DataFrame with all possible genotype combinations\n",
    "        all_combinations_df = pd.DataFrame(possible_genotypic_combinations, columns=snp_columns)\n",
    "\n",
    "        # Get the mean phenotype per SNP combination\n",
    "        geno_aggregations_train = snp_combination_df_train.groupby(snp_columns).agg(\n",
    "            mean_phenotype=('Phenotype', 'mean')\n",
    "        ).reset_index()  # Reset index to make the groupby columns as columns\n",
    "\n",
    "        anchor_mean = geno_aggregations_train['mean_phenotype'].iloc[\n",
    "            geno_aggregations_train['mean_phenotype'].first_valid_index()]  # The first valid genotype combination is considered as the anchor, it starts from (0,0) for 2-way epistasis\n",
    "\n",
    "        # Calculate the relative distance of the mean phenotype from the anchor\n",
    "        geno_aggregations_train['rel_dist'] = geno_aggregations_train['mean_phenotype'] - anchor_mean\n",
    "\n",
    "        # Min-Max normalization on rel_dist (relative distance)\n",
    "        scaler_train = MinMaxScaler()\n",
    "        geno_aggregations_train['normalized_rel_dist'] = scaler_train.fit_transform(\n",
    "            geno_aggregations_train['rel_dist'].values.reshape(-1, 1)\n",
    "        )\n",
    "\n",
    "        # Finding the missing multilocus genotypes\n",
    "        missing_combinations_df_train = pd.merge(all_combinations_df, geno_aggregations_train, on=snp_columns, how='left')\n",
    "        missing_combinations_train = missing_combinations_df_train[missing_combinations_df_train['mean_phenotype'].isnull()]\n",
    "\n",
    "        # Reset index\n",
    "        missing_combinations_train = missing_combinations_train.reset_index(drop=True)\n",
    "\n",
    "        # Convert missing combinations to comma-separated string of tuples\n",
    "        missing_multilocus_genotypes_train = missing_combinations_train[snp_columns].apply(tuple, axis=1)\n",
    "\n",
    "        # Create a DataFrame for the SNP combination with all missing genotypes\n",
    "        if len(missing_multilocus_genotypes_train) > 0:\n",
    "            df_to_add = pd.DataFrame([{\n",
    "                **dict(zip([f'SNP{i+1}' for i in range(order)], snp_combination)),\n",
    "                'Missing_Multilocus_Genotype': ','.join(map(str, missing_multilocus_genotypes_train))\n",
    "            }])\n",
    "            missing_multilocus_list.append(df_to_add)\n",
    "\n",
    "        # Store geno_aggregations for the current SNP combination\n",
    "        pager_epistasis_mapping.append(geno_aggregations_train)\n",
    "\n",
    "    # Concatenate all the missing multilocus dataframes\n",
    "    all_missing_multilocus_df = pd.concat(missing_multilocus_list, ignore_index=True)\n",
    "\n",
    "    return pager_epistasis_mapping, all_missing_multilocus_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define a function to take as input the original genotype data, the PAGER Epistatis mapping and order to create the new PAGER Epistatis dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pager_epistatis_dataset(genotypes, pager_epistatis_mapping, order):\n",
    "    \n",
    "    # DataFrame to store newly created PAGER epistatic dataset\n",
    "    pager_epistatis_dataset = pd.DataFrame()\n",
    "\n",
    "    # Dictionary to store the epistasis features before concatenating\n",
    "    epistasis_features = {}\n",
    "\n",
    "    # all possible SNP/feature combination for order-way epistasis\n",
    "    snp_combinations = list(combinations(genotypes.columns, order))\n",
    "\n",
    "    # Loop through each SNP combination and merge with corresponding geno_aggregations\n",
    "    for snp_combination, pager_epistatis_mapping in zip(snp_combinations, pager_epistatis_mapping):\n",
    "        snp_combination_genotypes = genotypes[list(snp_combination)]\n",
    "        snp_columns = list(snp_combination_genotypes.columns)\n",
    "\n",
    "        # Merge test data with normalized_rel_dist from training aggregation\n",
    "        merged_df_test = pd.merge(snp_combination_genotypes, pager_epistatis_mapping, on=snp_columns, how='left')\n",
    "\n",
    "        # Create a new column with the interaction feature for the test data\n",
    "        col_name = '_'.join(snp_columns)\n",
    "        #pager_epistatis_dataset[col_name] = merged_df_test['normalized_rel_dist']\n",
    "\n",
    "        # Store the column in the dictionary\n",
    "        epistasis_features[col_name] = merged_df_test['normalized_rel_dist']\n",
    "    \n",
    "    pager_epistatis_dataset = pd.concat(epistasis_features, axis=1)\n",
    "\n",
    "\n",
    "    return pager_epistatis_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create the PAGER epistatic features using the above defined function - Dataset 1 (Continuous phenotype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1.281788173_10.84091208  1.281788173_7.129118847  \\\n",
      "0                    0.454190                 0.484567   \n",
      "1                    0.473343                 1.000000   \n",
      "2                    0.072273                 0.526460   \n",
      "3                    0.373219                 0.526460   \n",
      "4                    0.072273                 0.444915   \n",
      "...                       ...                      ...   \n",
      "2778                 0.072273                 0.444915   \n",
      "2779                 0.349106                 0.382835   \n",
      "2780                 0.541761                 0.526460   \n",
      "2781                 0.541761                 0.444915   \n",
      "2782                 0.373219                 0.526460   \n",
      "\n",
      "      1.281788173_5.107167969  1.281788173_19.24321261  \\\n",
      "0                    0.222862                 0.642402   \n",
      "1                    0.780433                 0.725770   \n",
      "2                    0.444723                 0.311322   \n",
      "3                    0.488342                 0.311322   \n",
      "4                    0.444723                 0.311322   \n",
      "...                       ...                      ...   \n",
      "2778                 0.000000                 0.311322   \n",
      "2779                 0.497106                 0.642402   \n",
      "2780                 0.444723                 0.311322   \n",
      "2781                 0.444723                 0.311322   \n",
      "2782                 0.000000                 0.708543   \n",
      "\n",
      "      1.281788173_4.178946041  1.281788173_3.136492861  1.281788173_7.8599340  \\\n",
      "0                    0.243804                 0.153564               0.260949   \n",
      "1                    1.000000                 1.000000               0.916415   \n",
      "2                    0.244506                 0.000000               0.447534   \n",
      "3                    0.597303                 0.000000               0.261158   \n",
      "4                    0.244506                 0.220559               0.261158   \n",
      "...                       ...                      ...                    ...   \n",
      "2778                 0.076695                 0.000000               0.604372   \n",
      "2779                 0.243804                 0.153564               0.260949   \n",
      "2780                 0.244506                 0.000000               0.261158   \n",
      "2781                 0.244506                 0.220559               0.261158   \n",
      "2782                 0.597303                 0.000000               0.261158   \n",
      "\n",
      "      1.281788173_18.27348077  1.281788173_18.32316331  \\\n",
      "0                    0.303848                 0.011502   \n",
      "1                    0.609040                 0.619164   \n",
      "2                    0.175930                 0.000000   \n",
      "3                    0.175930                 0.000000   \n",
      "4                    0.175930                 0.000000   \n",
      "...                       ...                      ...   \n",
      "2778                 0.175930                 0.000000   \n",
      "2779                 0.000000                 0.011502   \n",
      "2780                 0.175930                 0.000000   \n",
      "2781                 0.736997                 0.000000   \n",
      "2782                 0.201939                 0.000000   \n",
      "\n",
      "      1.281788173_1.203085725  ...  9.15866960_9.71715296  \\\n",
      "0                    0.284408  ...               0.553112   \n",
      "1                    0.412449  ...               0.564769   \n",
      "2                    0.113140  ...               0.564769   \n",
      "3                    0.122843  ...               0.564769   \n",
      "4                    0.113140  ...               0.719805   \n",
      "...                       ...  ...                    ...   \n",
      "2778                 0.331750  ...               0.663198   \n",
      "2779                 0.000000  ...               0.564769   \n",
      "2780                 0.113140  ...               0.553112   \n",
      "2781                 0.331750  ...               0.564769   \n",
      "2782                 0.331750  ...               0.663198   \n",
      "\n",
      "      9.15866960_6.29889998  9.15866960_8.103608382  9.15866960_5.72916242  \\\n",
      "0                  0.159699                0.214823               0.257274   \n",
      "1                  0.000000                0.076217               0.000000   \n",
      "2                  0.000000                0.692408               0.000000   \n",
      "3                  0.529306                0.692408               0.432813   \n",
      "4                  0.000000                0.076217               0.432813   \n",
      "...                     ...                     ...                    ...   \n",
      "2778               0.628762                1.000000               0.330297   \n",
      "2779               0.529306                0.000000               0.599436   \n",
      "2780               0.251514                0.214823               0.079839   \n",
      "2781               0.529306                0.692408               0.599436   \n",
      "2782               0.628762                0.428939               0.330297   \n",
      "\n",
      "      9.71715296_6.29889998  9.71715296_8.103608382  9.71715296_5.72916242  \\\n",
      "0                  0.000000                0.027024               0.252387   \n",
      "1                  0.000000                0.027024               0.081246   \n",
      "2                  0.000000                0.259325               0.081246   \n",
      "3                  0.239539                0.259325               0.252387   \n",
      "4                  0.160599                0.376599               0.407610   \n",
      "...                     ...                     ...                    ...   \n",
      "2778               0.000000                0.259325               0.081246   \n",
      "2779               0.239539                0.020144               0.370620   \n",
      "2780               0.239539                0.027024               0.081246   \n",
      "2781               0.239539                0.259325               0.370620   \n",
      "2782               0.000000                0.027024               0.081246   \n",
      "\n",
      "      6.29889998_8.103608382  6.29889998_5.72916242  8.103608382_5.72916242  \n",
      "0                   0.000000               0.287761                0.450961  \n",
      "1                   0.000000               0.000000                0.154408  \n",
      "2                   0.315907               0.000000                0.467503  \n",
      "3                   0.678483               0.416787                0.549155  \n",
      "4                   0.000000               0.287761                0.450961  \n",
      "...                      ...                    ...                     ...  \n",
      "2778                0.315907               0.000000                0.467503  \n",
      "2779                0.084898               0.630493                0.379403  \n",
      "2780                0.194179               0.250712                0.154408  \n",
      "2781                0.678483               0.630493                1.000000  \n",
      "2782                0.000000               0.000000                0.154408  \n",
      "\n",
      "[2783 rows x 153 columns]\n",
      "           SNP1         SNP2 Missing_Multilocus_Genotype\n",
      "0   10.84091208   9.71715296                      (0, 0)\n",
      "1   7.129118847   9.71715296                      (2, 0)\n",
      "2   5.107167969   9.71715296                      (1, 0)\n",
      "3   19.24321261   9.71715296                      (0, 0)\n",
      "4     7.8599340   9.71715296                      (2, 0)\n",
      "5   18.27348077  18.32316331                      (2, 0)\n",
      "6   18.27348077   9.71715296                      (0, 0)\n",
      "7   18.32316331  1.203085725                      (0, 0)\n",
      "8   18.32316331  2.241577141                      (0, 0)\n",
      "9   18.32316331   9.71715296                      (0, 0)\n",
      "10  1.203085725   9.71715296                      (2, 0)\n",
      "11  10.23267180  2.241577141                      (2, 0)\n",
      "12  10.23267180   9.71715296                      (2, 0)\n",
      "13  2.241577141   9.71715296               (1, 0),(0, 0)\n",
      "14   9.15866960   9.71715296                      (0, 0)\n",
      "15   9.71715296   6.29889998                      (0, 1)\n",
      "16   9.71715296  8.103608382                      (0, 0)\n",
      "17   9.71715296   5.72916242                      (0, 0)\n"
     ]
    }
   ],
   "source": [
    "# read the genotypes and phenotype data\n",
    "data = pd.read_csv('/Users/ghosha/Documents/VSCode Projects/PAGER/data/XOR_2way_cont.csv')\n",
    "genotypes = data.iloc[:, :-1]\n",
    "phenotype = data.iloc[:, -1]\n",
    "order = 2\n",
    "\n",
    "# Split the data into training and testing - the recommended split is 50% training and 50% testing\n",
    "genotypes_train, genotypes_test, phenotype_train, phenotype_test = train_test_split(genotypes, phenotype, test_size=0.5, random_state=42)\n",
    "\n",
    "# Generate the PAGER epistasis encodings using the training genotypes and phenotype\n",
    "pager_epistasis_mapping,all_missing_multilocus = get_pager_epistatis_mapping(genotypes_train, phenotype_train, order)\n",
    "\n",
    "# Generate the PAGER epistasis dataset using the test genotypes and the PAGER epistasis mapping\n",
    "pager_epistatis_dataset = generate_pager_epistatis_dataset(genotypes_test, pager_epistasis_mapping, order)\n",
    "\n",
    "# impute missing values with 0.5\n",
    "pager_epistatis_dataset.fillna(0.5, inplace=True)\n",
    "\n",
    "# print the PAGER epistasis dataset\n",
    "print(pager_epistatis_dataset)\n",
    "# save the PAGER epistasis dataset\n",
    "pager_epistatis_dataset.to_csv('/Users/ghosha/Documents/VSCode Projects/PAGER/data/pager_epistatis_dataset.csv', index=False)\n",
    "\n",
    "# print the missing multilocus genotypes\n",
    "print(all_missing_multilocus)\n",
    "# save the missing multilocus genotypes\n",
    "all_missing_multilocus.to_csv('/Users/ghosha/Documents/VSCode Projects/PAGER/data/all_missing_multilocus.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create the PAGER epistatic features using the above defined function - Dataset 2 (Discrete phenotype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         N0_N1     N0_N2     N0_N3     N0_N4     N0_N5     N0_N6     N0_N7  \\\n",
      "0     0.848908  1.000000  0.199269  0.668466  0.428066  0.595156  0.572988   \n",
      "1     0.754143  0.802856  0.164428  0.041588  0.297228  0.375868  0.331636   \n",
      "2     0.775450  0.889243  0.199269  0.803534  0.077461  0.595156  0.572988   \n",
      "3     0.615910  0.925346  0.119380  0.044444  0.000000  0.360406  0.000000   \n",
      "4     0.775450  0.889243  0.199269  0.378164  0.428066  0.595156  0.393683   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2495  0.775450  0.910622  0.199269  0.668466  0.394925  0.490924  1.000000   \n",
      "2496  1.000000  0.889243  0.199269  0.668466  0.394925  0.490924  0.393683   \n",
      "2497  0.754143  0.802856  0.164428  1.000000  0.297228  0.375868  0.383011   \n",
      "2498  0.754143  0.666632  0.164428  0.041588  0.533732  0.375868  0.331636   \n",
      "2499  0.848908  0.889243  0.199269  0.378164  0.394925  0.490924  0.572988   \n",
      "\n",
      "         N0_N8     N0_N9    N0_N10  ...   N15_N16   N15_N17  N15_M0P1  \\\n",
      "0     0.895579  1.000000  0.520180  ...  0.513112  0.582841  0.567317   \n",
      "1     0.186970  0.843982  0.666851  ...  1.000000  0.756459  0.508383   \n",
      "2     0.895579  1.000000  0.520180  ...  0.193578  0.599861  0.419993   \n",
      "3     0.000000  0.789380  0.131303  ...  1.000000  0.475013  0.508383   \n",
      "4     0.895579  1.000000  0.520180  ...  0.505319  0.213115  0.669420   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "2495  0.987485  1.000000  0.520180  ...  0.193578  0.475013  0.508383   \n",
      "2496  0.987485  1.000000  1.000000  ...  0.505319  1.000000  0.669420   \n",
      "2497  0.962080  0.843982  0.380920  ...  0.577663  0.756459  0.419993   \n",
      "2498  0.962080  0.843982  0.877597  ...  0.513112  0.582841  0.567317   \n",
      "2499  0.895579  1.000000  1.000000  ...  0.577663  0.756459  0.631870   \n",
      "\n",
      "      N15_M0P2   N16_N17  N16_M0P1  N16_M0P2  N17_M0P1  N17_M0P2  M0P1_M0P2  \n",
      "0     1.000000  0.132575  0.716396  0.930355  0.689629  0.513882   0.137901  \n",
      "1     0.726520  0.132575  0.716396  0.334005  0.689629  0.284655   1.000000  \n",
      "2     0.158982  0.256817  0.000000  0.000000  0.938604  0.407167   0.956085  \n",
      "3     0.726520  0.305215  0.716396  0.334005  0.863515  0.508937   1.000000  \n",
      "4     0.309887  0.429390  0.668137  0.653847  0.689629  0.284655   1.000000  \n",
      "...        ...       ...       ...       ...       ...       ...        ...  \n",
      "2495  0.726520  0.034477  0.325313  0.360469  0.863515  0.508937   1.000000  \n",
      "2496  0.309887  0.307160  0.668137  0.653847  0.863515  0.508937   1.000000  \n",
      "2497  0.158982  0.429390  0.339770  0.625421  0.550693  1.000000   0.956085  \n",
      "2498  0.000000  0.132575  0.716396  0.334005  0.689629  0.284655   1.000000  \n",
      "2499  0.158982  0.429390  0.455314  0.625421  1.000000  1.000000   0.038960  \n",
      "\n",
      "[2500 rows x 190 columns]\n",
      "   SNP1  SNP2 Missing_Multilocus_Genotype\n",
      "0    N0    N3               (1, 2),(2, 2)\n",
      "1    N0   N11                      (2, 2)\n",
      "2    N1    N3               (0, 2),(2, 2)\n",
      "3    N1   N11                      (2, 2)\n",
      "4    N2    N3               (0, 2),(2, 2)\n",
      "5    N3    N4               (2, 0),(2, 2)\n",
      "6    N3    N5               (2, 0),(2, 2)\n",
      "7    N3    N6               (2, 0),(2, 1)\n",
      "8    N3    N7               (2, 1),(2, 2)\n",
      "9    N3    N8               (2, 1),(2, 2)\n",
      "10   N3    N9               (2, 0),(2, 2)\n",
      "11   N3   N10               (2, 1),(2, 2)\n",
      "12   N3   N11        (1, 2),(2, 1),(2, 2)\n",
      "13   N3   N12               (2, 0),(2, 2)\n",
      "14   N3   N13               (2, 0),(2, 1)\n",
      "15   N3   N14               (2, 0),(2, 2)\n",
      "16   N3   N15               (2, 1),(2, 2)\n",
      "17   N3   N16               (2, 1),(2, 2)\n",
      "18   N3   N17               (2, 1),(2, 2)\n",
      "19   N3  M0P1               (2, 1),(2, 2)\n",
      "20   N3  M0P2               (2, 1),(2, 2)\n",
      "21   N6   N11                      (2, 2)\n",
      "22  N11   N12                      (2, 2)\n"
     ]
    }
   ],
   "source": [
    "# read the genotypes and phenotype data\n",
    "data = pd.read_csv('/Users/ghosha/Documents/VSCode Projects/PAGER/data/XOR_2way_disc.csv')\n",
    "genotypes = data.iloc[:, :-1]\n",
    "phenotype = data.iloc[:, -1]\n",
    "order = 2\n",
    "\n",
    "# Split the data into training and testing - the recommended split is 50% training and 50% testing\n",
    "genotypes_train, genotypes_test, phenotype_train, phenotype_test = train_test_split(genotypes, phenotype, test_size=0.5, random_state=42)\n",
    "\n",
    "# Generate the PAGER epistasis encodings using the training genotypes and phenotype\n",
    "pager_epistasis_mapping,all_missing_multilocus = get_pager_epistatis_mapping(genotypes_train, phenotype_train, order)\n",
    "\n",
    "# Generate the PAGER epistasis dataset using the test genotypes and the PAGER epistasis mapping\n",
    "pager_epistatis_dataset = generate_pager_epistatis_dataset(genotypes_test, pager_epistasis_mapping, order)\n",
    "\n",
    "# impute missing values with 0.5\n",
    "pager_epistatis_dataset.fillna(0.5, inplace=True)\n",
    "\n",
    "# print the PAGER epistasis dataset\n",
    "print(pager_epistatis_dataset)\n",
    "# save the PAGER epistasis dataset\n",
    "pager_epistatis_dataset.to_csv('/Users/ghosha/Documents/VSCode Projects/PAGER/data/pager_epistatis_dataset.csv', index=False)\n",
    "\n",
    "# print the missing multilocus genotypes\n",
    "print(all_missing_multilocus)\n",
    "# save the missing multilocus genotypes\n",
    "all_missing_multilocus.to_csv('/Users/ghosha/Documents/VSCode Projects/PAGER/data/all_missing_multilocus.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: User can use the newly generated dataset to run a statistical (p-value based) or machine learning method of ranking interactions to check for the top features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edge_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
